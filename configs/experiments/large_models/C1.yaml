model:
  name: "kamel-usp/jbcs2025_bertimbau-large-C1"
  type: "encoder_classification"
  num_labels: 6
  output_dir: "./results/bertimbau_large/C1"
  logging_dir: "./logs/bertimbau_large/C1"
  best_model_dir: "./results/bertimbau_large/C1/best_model"

tokenizer:
  name: "neuralmind/bert-large-portuguese-cased"

dataset:
  grade_index: 0

training_params:
  weight_decay: 0.01
  warmup_ratio: 0.1
  learning_rate: 5e-5
  train_batch_size: 16
  eval_batch_size: 16
  gradient_accumulation_steps: 1
  gradient_checkpointing: False