model:
  name: "neuralmind/bert-large-portuguese-cased"
  type: "encoder_classification"
  num_labels: 6
  output_dir: "./results/bertimbau_large/C4"
  logging_dir: "./logs/bertimbau_large/C4"
  best_model_dir: "./results/bertimbau_large/C4/best_model"

dataset:
  grade_index: 3

training_id: "bertimbau-large-C4"

training_params:
  weight_decay: 0.01
  warmup_ratio: 0.1
  learning_rate: 5e-5
  train_batch_size: 16
  eval_batch_size: 16
  gradient_accumulation_steps: 1
  gradient_checkpointing: False