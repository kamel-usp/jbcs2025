{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cedebce",
   "metadata": {},
   "source": [
    "# Tokenization Analysis\n",
    "\n",
    "This notebook analyzes the average sequence length after tokenization for different models and tokenizers.\n",
    "This helps validate which models can receive different tokenization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc38677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import logging\n",
    "\n",
    "# Add parent directory to path\n",
    "parent_dir = str(Path(\".\").resolve().parent) + \"/scripts\"\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from preprocess import load_tokenizer, get_tokenize_function #NOQA\n",
    "from models.fine_tuning_models.model_types_enum import ModelTypesEnum #NOQA\n",
    "\n",
    "# Set up logging with a specific handler that we can control\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to clear logs\n",
    "def clear_logs():\n",
    "    \"\"\"Clear all handlers to prevent log accumulation\"\"\"\n",
    "    # Get all loggers\n",
    "    loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "    loggers.append(logging.getLogger())  # Add root logger\n",
    "    \n",
    "    # Clear handlers for each logger\n",
    "    for logger_instance in loggers:\n",
    "        handlers = logger_instance.handlers[:]\n",
    "        for handler in handlers:\n",
    "            handler.close()\n",
    "            logger_instance.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137840a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fccd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "dataset_name = \"kamel-usp/aes_enem_dataset\"\n",
    "dataset_split = \"JBCS2025\"\n",
    "cache_dir = \"/tmp/\"\n",
    "\n",
    "# Model configurations to test\n",
    "model_configs = [\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.PHI4_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"microsoft/phi-4\",\n",
    "        \"name\": \"Phi-4\",\n",
    "        \"use_full_context\": False\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.PHI35_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"microsoft/Phi-3.5-mini-instruct\",\n",
    "        \"name\": \"Phi-3.5\",\n",
    "        \"use_full_context\": False\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.LLAMA31_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"meta-llama/Llama-3.1-8B\",\n",
    "        \"name\": \"Llama-3.1\",\n",
    "        \"use_full_context\": False\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.ENCODER_CLASSIFICATION.value,\n",
    "        \"base_model\": \"neuralmind/bert-base-portuguese-cased\",\n",
    "        \"name\": \"Bertimbau Base\",\n",
    "        \"use_full_context\": False\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.ENCODER_CLASSIFICATION.value,\n",
    "        \"base_model\": \"google-bert/bert-base-multilingual-cased\",\n",
    "        \"name\": \"Bert Multilingual\",\n",
    "        \"use_full_context\": False\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.PHI4_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"microsoft/phi-4\",\n",
    "        \"name\": \"Phi-4-FullContext\",\n",
    "        \"use_full_context\": True\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.PHI35_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"microsoft/Phi-3.5-mini-instruct\",\n",
    "        \"name\": \"Phi-3.5-FullContext\",\n",
    "        \"use_full_context\": True\n",
    "    },\n",
    "    {\n",
    "        \"model_type\": ModelTypesEnum.LLAMA31_CLASSIFICATION_LORA.value,\n",
    "        \"base_model\": \"meta-llama/Llama-3.1-8B\",\n",
    "        \"name\": \"Llama-3.1-FullContext\",\n",
    "        \"use_full_context\": True\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# Grade indices to test (0-4 for C1-C5)\n",
    "grade_indices = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78debc69",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c187b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 500 training samples\n",
      "Dataset splits: ['train', 'validation', 'test']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\n",
    "    dataset_name,\n",
    "    dataset_split,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded with {len(dataset['train'])} training samples\")\n",
    "print(f\"Dataset splits: {list(dataset.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07df8a",
   "metadata": {},
   "source": [
    "## Tokenization Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a9c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tokenization(dataset, tokenizer, model_type, grade_index, text_column=\"essay_text\", logger=None, use_full_context=False):\n",
    "    \"\"\"\n",
    "    Analyze tokenization for a specific model and grade index.\n",
    "    Returns statistics about sequence lengths.\n",
    "    \"\"\"\n",
    "    # Get the tokenization function\n",
    "    tokenize_function = get_tokenize_function(\n",
    "        model_type=model_type,\n",
    "        tokenizer=tokenizer,\n",
    "        text_column=text_column,\n",
    "        grade_index=grade_index,\n",
    "        logger=logger,\n",
    "        use_full_context=use_full_context\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Apply tokenization\n",
    "    tokenized_sample = dataset['train'].map(tokenize_function, batched=True)\n",
    "    \n",
    "    # Extract sequence lengths\n",
    "    sequence_lengths = []\n",
    "    for example in tokenized_sample:\n",
    "        if 'input_ids' in example:\n",
    "            sequence_lengths.append(len(example['input_ids']))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'mean': np.mean(sequence_lengths),\n",
    "        'std': np.std(sequence_lengths),\n",
    "        'min': np.min(sequence_lengths),\n",
    "        'max': np.max(sequence_lengths),\n",
    "        'median': np.median(sequence_lengths),\n",
    "        'p95': np.percentile(sequence_lengths, 95),\n",
    "        'p99': np.percentile(sequence_lengths, 99)\n",
    "    }\n",
    "    \n",
    "    return stats, sequence_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0386dd4",
   "metadata": {},
   "source": [
    "## Run Tokenization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0faa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Phi-4 (microsoft/phi-4)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:02,138 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc51d85a28b340ceada1d2f3079a61e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:03,529 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d206e1808704a93abfb45935669db7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:05,443 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344df0fe7314036993b46c2821f913e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:07,013 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4836b86dadf84329a26c2bf7a64bb719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:08,583 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62792c7312c4302823524254c07555d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Phi-3.5 (microsoft/Phi-3.5-mini-instruct)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:10,554 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64afbf78ca64e319ab272447c991423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:12,025 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05eac528e8d04ef591d9e279d357ff0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:14,067 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fbf62427824339bfe62e6ae121f511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:15,702 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051b4e709bea4cc0956476b5e554acc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:17,365 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753a2c916d3343aa83af32f2bc58e7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Llama-3.1 (meta-llama/Llama-3.1-8B)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:19,578 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20555e2bd98a4afeb283059caf65040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:21,010 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f527ebe2bb0f42479cb01cf5fa37d06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:23,008 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd64aa7035f4c69ae42b6a70177110e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:24,602 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9f75fed8ca4aaa8c8dbef46647f403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:26,189 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d256d4308b34bbabec31f2ee84cbac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Bertimbau Base (neuralmind/bert-base-portuguese-cased)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:28,178 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:28,446 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:28,717 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:28,985 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:29,255 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n",
      "\n",
      "Analyzing Bert Multilingual (google-bert/bert-base-multilingual-cased)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:29,946 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:30,230 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:30,511 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:30,793 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:31,073 - __main__ - INFO - Tokenizer function parameters- Padding:max_length; Truncation: True; Use Full Context: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n",
      "\n",
      "Analyzing Phi-4-FullContext (microsoft/phi-4)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:31,732 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a6206e4a74ac4bf039903d82ccc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:33,746 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8d1448544c4869a05e3a17a5f1dac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:36,339 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9147c5dafc045fca3b5ea3fbb798f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:38,610 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e50789a29e94cd48d0f7c5588e4945d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:40,818 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fffe957b8a4597ab1024c9df666245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Phi-3.5-FullContext (microsoft/Phi-3.5-mini-instruct)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:43,379 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da19a306a69b48bcb4b649eedd0b664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:45,443 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06c8b3f989e47c2844298292df42e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:48,171 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82735d4613c4ac9bf381f1786971f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:50,437 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91590451e8c8485ca6667e358e8399a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:52,690 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ca4ed45fc64b98babae33d6af85a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Llama-3.1-FullContext (meta-llama/Llama-3.1-8B)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:55,502 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48155d050064efeb2fb4ac8ebaed1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:05:57,554 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5481f3d6dddb4a1798ce92ff518de341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:06:00,192 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951f4110b45642d8b128c14117b00ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:06:02,439 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c5cc368fb545eaa340172e8eafbdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 15:06:04,689 - __main__ - INFO - Tokenizer function parameters- Padding:longest; Truncation: False; Use Full Context: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing grade C5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4146584907949ba8fab93dec2d7e19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store results\n",
    "results = []\n",
    "all_sequence_lengths = {}\n",
    "\n",
    "for config in model_configs:\n",
    "    model_type = config['model_type']\n",
    "    base_model = config['base_model']\n",
    "    model_name = config['name']\n",
    "    use_full_context = config.get('use_full_context', False)\n",
    "    \n",
    "    print(f\"\\nAnalyzing {model_name} ({base_model})...\")\n",
    "    \n",
    "    try:\n",
    "    # Load tokenizer\n",
    "        tokenizer = load_tokenizer(model_type, base_model, cache_dir)\n",
    "\n",
    "        for grade_index in grade_indices:\n",
    "            print(f\"  Processing grade C{grade_index + 1}...\")\n",
    "\n",
    "            # Clear logs before processing\n",
    "            clear_logs()\n",
    "\n",
    "            # Re-setup logger after clearing\n",
    "            logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            logger = logging.getLogger(__name__)\n",
    "\n",
    "            # Analyze tokenization\n",
    "            stats, seq_lengths = analyze_tokenization(\n",
    "                dataset=dataset,\n",
    "                tokenizer=tokenizer,\n",
    "                model_type=model_type,\n",
    "                grade_index=grade_index,\n",
    "                text_column=\"essay_text\",\n",
    "                logger=logger,\n",
    "                use_full_context=use_full_context\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            result = {\n",
    "                'model': model_name,\n",
    "                'model_type': model_type,\n",
    "                'grade': f'C{grade_index + 1}',\n",
    "                **stats\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "            # Store sequence lengths for visualization\n",
    "            key = f\"{model_name}_C{grade_index + 1}\"\n",
    "            all_sequence_lengths[key] = seq_lengths\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {model_name}: {str(e)}\")\n",
    "        continue\n",
    "    # Clear logs after each model\n",
    "    clear_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3eb270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "      <th>grade</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Phi-3.5</td>\n",
       "      <td>phi35_classification_lora</td>\n",
       "      <td>C4</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3181</td>\n",
       "      <td>3181</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>3181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Llama-3.1-FullContext</td>\n",
       "      <td>llama31_classification_lora</td>\n",
       "      <td>C4</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3909</td>\n",
       "      <td>3909</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>3909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bertimbau Base</td>\n",
       "      <td>encoder_classification</td>\n",
       "      <td>C4</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bert Multilingual</td>\n",
       "      <td>encoder_classification</td>\n",
       "      <td>C1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Llama-3.1-FullContext</td>\n",
       "      <td>llama31_classification_lora</td>\n",
       "      <td>C1</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3620</td>\n",
       "      <td>3620</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>3620.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                   model_type grade    mean  std  \\\n",
       "8                 Phi-3.5    phi35_classification_lora    C4  3181.0  0.0   \n",
       "38  Llama-3.1-FullContext  llama31_classification_lora    C4  3909.0  0.0   \n",
       "18         Bertimbau Base       encoder_classification    C4   512.0  0.0   \n",
       "20      Bert Multilingual       encoder_classification    C1   512.0  0.0   \n",
       "35  Llama-3.1-FullContext  llama31_classification_lora    C1  3620.0  0.0   \n",
       "\n",
       "     min   max  median     p95     p99  \n",
       "8   3181  3181  3181.0  3181.0  3181.0  \n",
       "38  3909  3909  3909.0  3909.0  3909.0  \n",
       "18   512   512   512.0   512.0   512.0  \n",
       "20   512   512   512.0   512.0   512.0  \n",
       "35  3620  3620  3620.0  3620.0  3620.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70549e82",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd527b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sequence Length by Model and Grade:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>grade</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bert Multilingual</th>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bertimbau Base</th>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1</th>\n",
       "      <td>2479.0</td>\n",
       "      <td>3470.0</td>\n",
       "      <td>2774.0</td>\n",
       "      <td>2768.0</td>\n",
       "      <td>2921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama-3.1-FullContext</th>\n",
       "      <td>3620.0</td>\n",
       "      <td>4611.0</td>\n",
       "      <td>3915.0</td>\n",
       "      <td>3909.0</td>\n",
       "      <td>4062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3.5</th>\n",
       "      <td>2775.0</td>\n",
       "      <td>4042.0</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>3181.0</td>\n",
       "      <td>3349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-3.5-FullContext</th>\n",
       "      <td>4093.0</td>\n",
       "      <td>5360.0</td>\n",
       "      <td>4511.0</td>\n",
       "      <td>4499.0</td>\n",
       "      <td>4667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-4</th>\n",
       "      <td>2489.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>2932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-4-FullContext</th>\n",
       "      <td>3629.0</td>\n",
       "      <td>4621.0</td>\n",
       "      <td>3925.0</td>\n",
       "      <td>3920.0</td>\n",
       "      <td>4072.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "grade                      C1      C2      C3      C4      C5\n",
       "model                                                        \n",
       "Bert Multilingual       512.0   512.0   512.0   512.0   512.0\n",
       "Bertimbau Base          512.0   512.0   512.0   512.0   512.0\n",
       "Llama-3.1              2479.0  3470.0  2774.0  2768.0  2921.0\n",
       "Llama-3.1-FullContext  3620.0  4611.0  3915.0  3909.0  4062.0\n",
       "Phi-3.5                2775.0  4042.0  3193.0  3181.0  3349.0\n",
       "Phi-3.5-FullContext    4093.0  5360.0  4511.0  4499.0  4667.0\n",
       "Phi-4                  2489.0  3481.0  2785.0  2780.0  2932.0\n",
       "Phi-4-FullContext      3629.0  4621.0  3925.0  3920.0  4072.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Average Sequence Length by Model and Grade:\")\n",
    "pivot_table = results_df.pivot_table(\n",
    "    values='mean', \n",
    "    index='model', \n",
    "    columns='grade', \n",
    "    aggfunc='first'\n",
    ")\n",
    "pivot_table.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
